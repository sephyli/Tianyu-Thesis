% !Mode:: "TeX:UTF-8"
\chapter{绪论}

\section{简介}

\subsection{研究背景}

计算机视觉是计算机通过分析图像来获取图像中信息的能力，具有极其广泛的应用，如人脸识别、自动驾驶、视觉导航、医学影像分析等。计算机视觉领域的发展与人类生活的各个领域息息相关，而现如今，通过多样的机器学习技术提升计算机视觉系统的分析能力，成为当今计算机视觉研究领域亟待解决的问题。

对许多计算机视觉领域的经典任务而言，卷积神经网络（Convolutional Neural Networks, CNN）在多年的发展中取得了良好的成果。CNN针对网格式数据设计，在图片这样的矩阵型数据上具有很强的拟合能力，从而可以在很大程度上提取图像中像素级的信息和特征。因此，构建不同网络结构的CNN，并通过执行图像分类\cite{He2016DeepRL}等视觉任务，验证CNN提取特征的能力，一直以来都是本领域研究的热点。

\begin{figure}
    \centering
    \includegraphics[width=.8\textwidth]{figure/visual.png}
    \caption{本图中的办公桌上存在着多种物体间的语义关系}
    \label{fig:relation_sample}
\end{figure}

但是在目标检测\cite{Ren2015FasterRT}、区域分类\cite{Chen2018IterativeVR}、语义分割等任务中，图像中的物体在种类和数目上都较为复杂，物体间也具有多样化的关系。多样的物体种类和有限的数据使很多不常见的分类仅仅有很少的训练样例，还有严重遮挡、模糊等现象。而传统的视觉模型往往只对物体所在的局部区域进行分析，那么模型在这种较稀有分类上的表现就十分糟糕。如果模型能学习到图像的全局上下文信息，就可以借助其他常见分类与稀有分类间的关系，来提升模型在稀有分类上的表现。

在识别场景中的物体时，人类往往能通过多种关系来做出推理判断。如图\ref{fig:relation_sample}，这个办公桌的场景在生活中十分常见。当人一看到办公桌上的显示器，就会自动从记忆中调取信息，进而得知显示器附近会存在键盘、鼠标等物体。与人类很自然地通过常识性语义关系或空间关系辅助认知不同，传统的视觉模型缺少这样视觉推理的能力，也就是通过利用图像中的额外信息进行推理，增强视觉模型识别物体的能力。

本研究基于图像数据，构建图结构的知识图谱（Knowledge Graph, KG）来保存物体之间的关系。近年提出的图卷积网络（Graph Convolution Networks, GCN）可以有效提取图结构上的特征，并完成网络节点分类等任务\upcite{Kipf2017SemiSupervisedCW}。因此，本研究将通过GCN和知识图谱分析图像中物体间的关系信息，结合传统CNN对图像像素信息的提取能力，设计一种效率更高的新型视觉推理模型，以获得更好的区域分类效果，从而满足计算机视觉研究在自动驾驶等领域应用上的需求。

\section{国内外研究现状}

\subsection{视觉知识库}

计算机视觉领域的快速发展离不开公开大规模数据集的完善，从最简单的对物体对象的标注\cite{Lin2014MicrosoftCC, Russakovsky2015ImageNetLS}，到对场景信息的标注\cite{Zhou2018SemanticUO}，到对关系信息的标注\cite{Krishna2016VisualGC}等等。上述数据集的建立使依赖大量数据的卷积神经网络更易于训练，也间接定义了对卷积神经网络的评判标准。

ImageNet\cite{Russakovsky2015ImageNetLS}图像分类数据集的发布极大地促进了计算机视觉领域中深度学习方法的发展。作为图像分类数据集，ImageNet的标准输入分辨率为$224 \times 224 \times 3$，其中3代表图像的通道数，即红、绿、蓝三通道。ImageNet数据集的图像分类挑战任务具有1,000个分类，但ImageNet数据集本身已经发展到具有一千四百万张图像与超过两万个分类，并且也具备作为目标检测数据集的能力。微软发布的COCO\cite{Lin2014MicrosoftCC}数据集是计算机视觉领域中重要的具有一定规模的目标检测和语义分割数据集，其图像来自较为复杂的生活场景，输入分辨率不定。COCO数据集具有超过二十二万张经过标注的图像，对目标检测任务具有91类，对语义分割任务具有80类。Visual Genome\cite{Krishna2016VisualGC}数据集作为大范围目标检测数据集，包含了众多高质量的标注信息，包括对象信息、对象属性信息、对象间关系信息等。VG数据集由是十万余张经过高质量标注的图片样例组成，并具有超过八万个分类，平均每张图片中出现21.24个对象，17.68个关系连接以及16.08个属性标注信息。作为目标检测挑战任务，VG数据集可采样为具有一千类的vg-1000或具有三千类的vg-3000。

\subsection{利用关系信息的计算机视觉研究}

在深度学习成为计算机视觉的主流方法之前，已经有很多传统的视觉算法利用了对象间关系来提升算法表现。Divvala等的研究\cite{Divvala2009AnES}使用对象间的共存关系来对检测到的对象进行重新评分，从而提升目标检测的成绩，也有一些研究指出对象间的空间关系可以改善图像分割的效果\cite{Galleguillos2008ObjectCU, Gould2008MultiClassSW}。

随着深度学习在视觉领域的广泛应用，在目标检测，区域分类，语义分割等任务中，均有许多研究利用了关系信息来提升视觉任务的表现\cite{Hu2017RelationNF, Jiang2018HybridKR, Chen2018IterativeVR, Xu2019ReasoningRCNNUA}。

X.Chen等的超越卷积的迭代视觉推理系统\cite{Chen2018IterativeVR}（Iterative Visual Reasoning Beyond Convolutions）将区域间的空间关系和语义关系构建成图，并利用图神经网络进行分析。该系统由两个模块组成，局部模块（Local Module）和全局模块（Global Module）。局部模块主要使用空间内存（Spacial Memory）实现，可以提取图像中的像素级信息，全局模块则是基于图结构的关系推理。该模型在全局模块中通过有效利用人类常识性知识图谱来直接为语义关系提供参考，且显式地标识出区域与区域间的空间关系，更好地利用了这些关系信息。全局模块的处理方法利用了图神经网络的思想,其模块内的关系图主要由三个部分组成，区域图（Region Graph）、知识图（Knowledge Graph）和分配图（Assignment Graph）。其节点分为区域节点（Region Nodes）和类节点（Class Nodes），区域节点表示一图像中的某一区域，类节点表示在数据集中出现的每一种类别。

另外，最近有一些研究将知识图谱和图神经网络结合用于计算机视觉问题。Li等的研究\cite{Li2017SituationRW}提出了一种基于图神经网络的情景识别方法，可以有效地分析角色间的联合依赖关系。一些研究\cite{Wang2018ZeroShotRV, Kampffmeyer2019RethinkingKG}利用知识图谱来解决难度较高的零样本识别任务。Yang等的研究\cite{Yang2018VisualSN}提出了一个视觉导航框架，该框架可以动态地对知识图谱进行更新，结合语义关系使视觉导航可以更好地泛化到未见场景。

\subsection{图卷积网络}

图神经网络\cite{Scarselli2009TheGN}是对结构化数据进行特征提取的有效网络结构，根据传播方式的不同，可细化为图卷积网络等不同形态。图卷积网络中卷积的引入使运算更切合信息在拓扑结构上传播的本质，这类卷积运算分为频域（Spectral Domain）和空域（Spatial Domain）两种。基于频域运算的图卷积网络\cite{Bruna2014SpectralNA, Kipf2017SemiSupervisedCW}使用特殊构造的卷积核，对图进行傅里叶变换，从而在频域进行运算。基于空域的图卷积网络\cite{Duvenaud2015ConvolutionalNO,Atwood2016DiffusionConvolutionalNN}将卷积操作定义在节点上，直接对其近邻节点进行操作。

一种先进的图注意力网络\cite{Velickovic2018GraphAN}（Graph Attention Networks, GAT）在空域图卷积网络的基础上，受机器翻译中的联合学习\cite{Bahdanau2015NeuralMT}启发，引入了注意力机制，通过自注意力策略计算每个节点和其近邻节点的一种隐式表达，可以应用在具有任意度的图节点上。

\section{研究方法}

\subsection{研究目标}

本研究的主要目标是使用基于注意力机制的图卷积网络和人类常识性知识图谱，构建对物体语义关系的高效分析结构，结合传统的卷积网络骨架提取图像的像素特征，从而使模型具备视觉推理能力，提升在Visual Genome数据集上的区域分类任务的分类准确性。

\subsection{关键技术}

1、知识图谱的构建

本研究提出的视觉推理模型的关键之处在于使用图卷积网络分析知识图谱，利用知识图谱中的物体间关系来使模型具备视觉推理能力。而物体间关系的质量是视觉推理能力强弱的关键。物体间关系主要分为语义关系和空间关系，前者是图像之外的，物体和物体之间本身存在的关系信息，后者是图像内的，物体与物体之间的空间关系的信息。

语义关系的知识图谱通过两种方式构建。通过人类常识性的物体间关系在整个数据集中的出现频率，可以构建出关系知识图谱；通过物体的属性分布的相关度，可以构建出属性知识图谱。

空间关系的知识图谱可以通过简单的物体间距离构建，通过计算物体所在区域的中心间距离，来计算某图像内区域间的空间关系强弱程度。由于区域会出现重叠现象，还可以通过计算重叠区域间的交并比(IoU)来增强空间关系的强度。

2、区域特征的提取与分配

普通的卷积神经网络可以提取整张图像的像素特征，但区域分类任务要对图像中某一部分区域做识别，因此需要提取该区域的区域特征。在不同分辨率的图像中的大小不一的区域，经过特征提取后应得到结构通用、维度大小相同的特征，而普通的全连接层或卷积运算都不能满足这一需求。因此本研究使用感兴趣区域层，对图像中各个区域的特征进行提取。

经过感兴趣区域层提取区域特征之后，CNN模块输出的区域特征，很自然地应与GCN模块中知识图谱的节点相对应。由于知识图谱的节点实际上代表着某一种物体类别，则应使用由CNN模块生成的初步预测，来指导区域特征对节点的分配。而本模型事实上期望经过GCN模块的视觉推理能力，从而纠正CNN模块对某些区域错误的初始预测，这意味着在视觉推理能力生效时，CNN模块对这一区域生成的分类的初步预测的第一个一定是错误的，但正确的分类也有很大概率在初步预测的前$k$个。因此，本模型使用软分配策略分配区域特征，使错误预测的区域也有一部分特征被分配到正确的节点上。即使错误的初始分类会使正确的节点接收到较少的区域特征，但随着区域特征沿关系传播，正确的分类之间存在着关系，则正确节点的置信度会由此而提高，错误节点的置信度也会随之下降。因此，使用软分类策略可以使模型对错误的分类更加鲁棒，增强模型纠正初始预测错误的能力。

3、区域特征的传播

在GCN模块中，区域特征沿知识图谱的边进行传播，而对不同的边，基于频率统计的边权只能反映在数据集中这种关系出现次数的多少，但对出现关系的某一张图片而言，稀少的关系和频繁而常见的关系的关系强度是近似的。对单张图片样例而言，直接使用边权来作为传播特征的比例，并不能直接代表这二者在此张图上出现关系的强弱，只能间接地说明这张图上出现此关系的概率较低。但某张图片出现关系时，应对这样的关系加以利用。因此，本模型使用了带注意力机制的图注意力层来传播区域的特征，意图使用注意力机学习到为具备关系的节点间提供更强的权重，对不具备关系的节点间提供较低的权重。

另外，基于一个常识性假设，距离更近的物体间关系更强，而距离较远的物体间即使本身在语义上具备关系，在图像中可能只是凑巧同时出现，而不具备相应关系。那么对区域特征的传播加入距离权重为权重的分配提供了新的基于空间距离的先验知识，由此来削弱距离较远、凑巧出现的物体间关系。

\subsection{研究方法}

1、对VG数据集的预处理和知识图谱构建

VG数据集含有超过100,000张图像数据。在官方网站上下载VG数据集，依据数据集中定义的数据文件格式，对数据集文件进行分析。其中包含着如城市、野外、室内等不同场景下的高质量标注数据，应调查VG数据集对物体的标注情况和标注质量，选取合适的对象集合用以构建训练集和验证、测试集。

设计管理数据集的工具，对数据集进行再包装，将图像、对象区域位置信息、对象间关系信息、对象属性信息等使用简明的数据结构进行管理，将其中冗余的数据条目删除，保留在训练中使用到的或构建知识图谱过程中使用到的相应条目。使用VG数据集中提供的对象间关系信息和对象属性信息构建语义知识图谱。

2、构建基线模型和加入了GCN模块的视觉推理模型

本研究的视觉推理模型主要分为两大模块，分别为CNN模块与GCN模块。前者通过使用最新的目标检测框架技术，负责提取图像特征以及图像中的区域特征，后者使用图注意力层构建，负责使区域特征沿知识图谱的边进行传播。

本研究主要通过构建基线模型和上述视觉推理模型，在相同的训练参数和条件下，相同的数据集和任务下，对选定的评价指标进行对比，从而体现本研究所提出方法的有效性和优越性。

\section{论文构成}

论文除绪论与相关技术陈述外，主要由两大部分构成：第一大部分，介绍知识图谱的构建与视觉推理模型框架的设计思路；第二大部分，介绍视觉推理模型的实现与训练细节，以及相关的实验。

在第一大部分中，首先介绍介绍知识图谱的构建，根据关系来源的不同，主要分为语义知识图谱和空间知识图谱两类，其中语义知识图谱根据由对象间关系构造，或由对象间属性相关度构造，又分为关系知识图谱和属性知识图谱。本文详细地介绍了知识图谱的构建方法及思想。

然后，介绍CNN模块的设计思路，使其能够具备较好的区域分类能力，这可以增强基线模型的表现，也为视觉推理模型在GCN模块中利用关系打下良好基础。CNN模块中包含卷积网络主干、特征金字塔网络、感兴趣区域层等技术，CNN模块最终可以提取图像的区域特征，以及对各个区域分类的初始预测。

最后，是视觉推理模型获得视觉推理模型的关键，GCN模块。在这一部分中，首先介绍了软分配策略，其决定了区域特征以怎样的方法对应到节点上，然后介绍普通图注意力层的设计思路，以及在本模型中，融合了知识图谱以及空间距离权重的图注意力层是怎么有效地传播正确地区域特征的。最后，介绍了GCN模块是如何对分类进行重新预测，从而更正错误的初始预测，并提升模型的分类准确率的。

在第二大部分中，首先介绍了本研究所针对的数据集，以及对数据集的预处理与在数据集上定义的区域分类任务；然后介绍了模型的训练参数等信息；最后，介绍了多组对比实验，从而分析本研究使用图注意力层在知识图谱上传播特征的有效性。

在全文最后，经过充分地讨论，得到了本研究的结论，以及本研究尚存在的一些不足，还包含对其未来改进空间的展望。