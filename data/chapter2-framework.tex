% !Mode:: "TeX:UTF-8"
\chapter{视觉推理模型}

本章节介绍组成视觉推理模型的整体框架，该框架由CNN模块和GCN模块组成，其中CNN模块负责提取图像中区域的像素特征，GCN模块负责将区域特征沿知识图谱的边进行传播。本章首先介绍CNN模块的主干设计，随后介绍GCN模块中区域特征分配的方法、图注意力层的设计以及区域特征传播的方法，最后，介绍模型的实现细节。

\section{CNN模块}

CNN模块的输入是图像及对象的无标签区域坐标。首先，经由CNN模块的卷积网络主干，提取图像的全局像素特征，然后使用感兴趣区域层，将全局特征依不同对象的区域坐标转化为区域特征，并将区域特征输出到下一模块，如图\ref{fig:cnn}。除提取特征之外，CNN模块也要做出对各区域分类的初步预测，以将区域特征与不同分类的节点相对应。

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figure/cnn.png}
    \caption{CNN模块图示}
    \label{fig:cnn}
\end{figure}

本模块使用了多种技术提升特征提取的能力，意图对大部分常见分类，生成较为准确的初始预测。使用这样的预测将区域特征输入GCN模块，GCN模块才可以更好地将区域特征在相应类别的节点间传播。

\subsection{卷积网络主干}

卷积网络主干的设计至关重要，这一部分主要负责提取图像的全局像素特征。在本研究所针对的区域分类任务中，包含所有对象的高分辨率图像直接输入到这一卷积网络进行降维，输出一个通道数较多，而特征图大小较小的高维特征。

受Mask R-CNN启发，本模块使用ResNet作为卷积网络主干，这一模型具备极强的特征提取能力，在以往的计算机视觉研究中得到了充分验证\upcite{He2016DeepRL, He2017MaskR}。ResNet使用残差连接，解决了以前的卷积神经网络在尝试加深层数时出现的梯度丢失问题，避免了网络的加深反而导致模型拟合能力变差的情况，这一设计使更深的、拟合能力更强的网络成为可能。本研究通过实验对比，选择了101层的ResNet以获得极强的特征提取能力，为模型学习到较难分类的特征提供基础。

本模块所使用的ResNet经过多层降维后，输出特征图到卷积网络主干尾部的特征金字塔网络。这一部分从ResNet的不同阶段接受不同尺寸的输入，从而生成结合不同分辨率特征的高质量特征。特征金字塔网络兼顾了速度与精度，可以充分的提取稀少样本和小样本物体的特征，大大地提升了卷积网络主干的特征提取能力。

\subsection{感兴趣区域层}

输入图像经由卷积网络主干提取全局像素特征后，输出的特征图最小为原分辨率的$1/32$。由于输入图像的分辨率不定，且图像中对象区域的大小也互不相等，则输出的特征图本身的大小就参差不齐，但GCN模块接受的输入应当是固定大小的特征向量。而传统的全连接层针对固定大小的输入设计，无法应用于本研究所处理的区域分类任务。因此，本模块加入了感兴趣区域层对各个大小不一的区域的特征进行提取。该感兴趣区域层使用精准的区域坐标，以及RoI Align层的实现，可以获得较为有效的区域特征。

\section{GCN模块}

GCN模块的结构由三大部分组成：软分类策略、区域特征在GCN上的传播和更新以及对分类的重新预测。

\subsection{软分类策略}

当模型的CNN模块输出各个对象的区域特征时，将区域特征与GCN中知识图谱的节点相对应便是亟待解决的问题。显然，关系存在于物体分类之间，即知识图谱的节点是由物体的分类所定义，而不是由某一张图像中的对象区域所定义的。那么，GCN模块需要将存在于知识图谱中的关系应用在任意一张图像样例上，首先，便需要得到图像样例中对象区域的初步分类。这一分类同样作为CNN模块的输出，是由CNN模块在提取特征后，应用一个分类器独自生成的。然后，将区域特征由区域特征生成的分类，分配至相应的知识图谱的节点上。

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figure/soft.png}
    \caption{软分类策略}
    \label{fig:soft}
\end{figure}

但是，错误的初始分类预测会导致区域特征被分配至错误的节点上。而在高难度的VG测试集上，一张样例上$50\%$左右的初始分类预测都是错误的。错误的初始分类会导致区域特征在错误分类的节点间传播，而知识图谱中的关系就难以利用。因此，相对于只将特征传递给初始分类预测中的最可信分类，本研究使用了软分类策略分配区域特征。

首先，对初始分类结果置信度排序的前$k$个分类分别计算Softmax值$S_{i}$。如式\ref{softmax}，其中$e^{i}$代表分类器输出的第$i$个分类的置信度。

\begin{equation} \label{softmax}
    S_{i}=\frac{e^{i}}{\sum_{j} e^{j}}
\end{equation}

由此得到前$k$个分类的置信概率分布，依此置信概率为分配权重，将区域特征按比例分配到相应的节点中，如图\ref{fig:soft}。

因为正确的分类往往都会出现在初始结果预测的前$k$个，因此对这一区域，其正确分类对应的节点有很大概率接收到该物体的区域特征。即使错误的初始预测会使正确的节点接收到较少的区域特征，但随着区域特征沿关系传播，正确的分类之间存在着关系，则正确的节点的置信度会由此而提高，错误的节点的置信度也会随之下降。这是因为，对于一个关系的两方而言，相对容易识别的一方一般具有正确的分类预测，而另一方的分类可能预测错误。软分类策略在保证了正确分类预测一方的正确节点可以接受到大量区域特征的同时，错误分类预测一方的正确节点也可以接受到区域特征。这为视觉推理模型在知识图谱上利用物体间关系提供了基础。因此，使用软分类策略可以使模型对错误的分类更加鲁棒，增强模型纠正初始预测错误的能力。

\subsection{区域特征在GCN上的传播}

当区域特征由CNN模块正确地通过软分类策略分配到知识图谱的各个节点上时，下一步就是让知识图谱节点上的特征沿知识图谱的边进行传播，在特征进行传播后，要进入分类预测器生成新的预测。知识图谱中的关系是不规则的，对单个节点所表示的对象来说，其关系的多寡是依据现实情况决定的。而我们需要将知识图谱中的不规则的关系融入各个节点区域的特征，更新区域特征后，融入了关系的特征就可以提升分类预测的准确率。受近年来在图卷积网络领域十分热门的图注意力网络\cite{Velickovic2018GraphAN}启发，本研究使用图注意力层作为本模块中传播区域特征的层。

1、图注意力层

图注意力层的输入是一个节点区域特征组成的集合，$\mathbf{h}=\left\{\vec{h}_{1}, \vec{h}_{2}, \ldots, \vec{h}_{N}\right\}, \vec{h}_{i} \in \mathbb{R}^{F}$，其中$N$为节点数量，在本任务中即为分类数量，$F$即为每个节点特征向量的长度。经过特征传播运算后，图注意力层输出新的特征集合$\mathbf{h}^{\prime}=\left\{\vec{h}_{1}^{\prime}, \vec{h}_{2}^{\prime}, \ldots, \vec{h}_{N}^{\prime}\right\}, \vec{h}_{i}^{\prime} \in \mathbb{R}^{F^{\prime}}$，其中$F^{\prime}$为输出特征的维度，根据实际情况可与输入特征的维度$F$相同或不同。

对于一个深度学习模型而言，可训练的参数是它学习到提取特征能力的必要因素。而图注意力层有两个可学习的参数，权重矩阵$\mathbf{W} \in \mathbb{R}^{F^{\prime} \times F}$与注意力机$\vec{\mathbf{a}} \in \mathbb{R}^{2 F^{\prime}}$。对于每个节点$i$，定义$\mathcal{N}_{i}$为所有节点$i$的一阶近邻，包括其自身。图注意力层应用了注意力机制，可以学习到节点与其一阶近邻传播特征的权重。对每个节点$j \in \mathcal{N}_{i}$，计算一个注意力系数$\alpha_{i j}$，如式\ref{GAT:attention}。

\begin{equation} \label{GAT:attention}
    \alpha_{i j}=\frac{\exp \left(\operatorname{LeakyReLU} \left(\vec{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{j}\right]\right)\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(\operatorname{LeakyReLU}\left(\vec{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{k}\right]\right)\right)}
\end{equation}

式中$\|$为向量拼接操作，操作$T$为矩阵转置，$\operatorname{LeakyReLU}(\cdot)$为非线性激活函数（参数$\alpha$为0.2），如式\ref{GAT:LeakyReLU}。将$\mathbf{W} \vec{h}_{i} \in \mathbb{R}^{F^{\prime} \times 1}$与$\mathbf{W} \vec{h}_{j} \in \mathbb{R}^{F^{\prime} \times 1}$沿第0维拼接后，与注意力机$\vec{\mathbf{a}}$做乘法运算得出节点$j$对$i$的注意力分量，再与所有节点的注意力分量之和做Softmax运算，得出注意力系数$\alpha_{i j}$。此时很容易看出，节点$i$的所有一阶近邻节点的注意力系数之和为1。

\begin{equation} \label{GAT:LeakyReLU}
    \operatorname{LeakyReLU}(x)=\left\{\begin{array}{ll}
    x, & x \geq 0 \\
    \alpha x, & x<0
    \end{array} \in R\right.
\end{equation}

那么便可以计算出节点$i$的输出特征向量$\vec{h}_{i}^{\prime}$，如式\ref{GAT:output1}，其中$\sigma(\cdot)$为非线性激活函数。

\begin{equation} \label{GAT:output1}
    \vec{h}_{i}^{\prime}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} \mathbf{W} \vec{h}_{j}\right)
\end{equation}

此外，参考CNN中卷积核的通道数，图注意力层也可以使用类似的机制，构建多个图注意力机$\vec{\mathbf{a}}_{k}$和权重矩阵$\mathbf{W}_{k}$，使训练过程更稳定，收敛更迅速。最终输出的特征向量为$k$个图注意力机输出的特征向量的拼接或均值。

2、区域特征的传播

在本模块中，区域特征沿知识图谱的边进行传播。对关系知识图谱而言，基于频率统计的边权反映的是在数据集中关系出现的频繁程度。但对出现关系的某一张图片而言，稀少的关系和频繁而常见的关系的关系强度是近似的。因此知识图谱的边权并不能直接代表在图片中，两个区域间关系的强弱，只能间接地说明这张图上出现此关系的概率高低。在数据集中，较为稀少的物体的关系也较为稀少，出现频次很低，如果直接使用知识图谱的边权作为区域特征传递的权重，会使模型对稀少分类的关系利用弱化。

因此，本模型使用了带注意力机制的图注意力层来传播区域的特征，意图使用注意力机学习到为具备关系的节点间提供更强的权重，对不具备关系的节点间提供较低的权重。

此外，基于一个常识性假设，图像中距离相近的物体分类之间具备语义关系的概率较大，而较远的物体分类间即使具备语义关系，也很有可能是巧合。如人与自行车两个对象，若二者距离较近，其可能发生的是人驾驶自行车的语义关系，但若实际情况中，自行车与人之间存在很远的间隔，那么二者的驾驶关系就十分微弱乃至不成立。除驾驶关系外，大部分的语义关系都发生于较近的对象之间，则为了防止这样错误的传播出现，应在应用语义关系时加入空间关系，来削弱距离较远的巧合情况，增强距离较近的强语义关系，从而改善对语义关系的利用。

因此，在计算特征传播的过程中，在知识图谱边权$e_{i j}$的基础上，额外加入一个像素距离权重$d_{i j}$，该权重的计算方式与空间知识图谱$G_{S}$的边权$e_{i j}^{S}$一致，如式\ref{Gs_edge}。则本模型中，节点$i$的特征向量$\vec{h}_{i}$经过一次传播后，输出特征向量$\vec{h}_{i}^{\prime}$的计算如式\ref{GAT:output2}。

\begin{equation} \label{GAT:output2}
    \vec{h}_{i}^{\prime}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} e_{i j} d_{i j} \mathbf{W} \vec{h}_{j}\right)
\end{equation}

因此，对注意力系数的计算改进为式\ref{GAT:attention2}，特别的，对节点$i$的区域特征$\vec{h}_{i}$，其距离权重$d_{i i}$和知识图谱边权$e_{i i}$均为1。将空间距离和知识图谱关系权重对近邻特征$\vec{h}_{j}$的影响加入计算，这样可以使注意力机学习到不同重要性的近邻对中心节点的区域特征传播的重要性不同，对重要性较高的近邻分配更多的传播注意力，这可以有效避免错误或不重要的关系，如较远的物体、多层传播中的非一阶近邻节点等对区域特征的传播产生过多的副作用。

\begin{equation} \label{GAT:attention2}
    \alpha_{i j}=\frac{\exp \left(\operatorname{LeakyReLU} \left(\vec{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| e_{i j} d_{i j} \mathbf{W} \vec{h}_{j}\right]\right)\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(\operatorname{LeakyReLU}\left(\vec{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| e_{i k} d_{i k} \mathbf{W} \vec{h}_{k}\right]\right)\right)}
\end{equation}


由于知识图谱中每一个分类都对应最少一个节点，实际上，依数据集不同，分类数量在数十到上万不等。若对知识图谱中的全部节点计算注意力机制，势必会消耗极多的运算资源和内存。但对单张图像样例来说，即使应用了软分类机制，图像中对象区域对应的节点数量也会远小于数据集中分类的总数。因此，当样例中的对象区域的特征依软分类机制被分配到对应的节点上之后，其它没有被对应的节点的特征值视作0，不会参与对其它节点的区域特征传播，在计算时也不以其为中心节点。这样大部分未参与节点就会被跳过，加速运算的同时，也不影响区域特征传播的正确性。

另一方面，若一张样例中，同时出现多个区域被分类到某个节点，在传播时会对这个节点的不同区域特征进行多次计算。实际计算时，将每个区域特征都当做一个新节点。对节点$i$进行计算时，各个相同分类的节点的关系连接权重$e_{i j}$使用知识图谱中此分类对应的边权，如果节点$i$本身有相同分类的节点，便使用知识图谱中的自连接权重进行传播，而对注意力系数$\alpha_{i j}$和距离权重$d_{i j}$，每个节点独立进行计算。另外基于软分类策略，每个区域特征都对应了多个节点，在分别计算这一区域的各个节点的输出特征后，将各个节点的输出特征相加，输出为本区域的输出特征。


\subsection{分类的重新预测}

在CNN模块的感兴趣区域层，或GCN模块的图注意力层计算出某一阶段的区域特征后，模型都会使用分类器对区域进行分类。区域特征经过图注意力层传播之后，初始分类正确的对象可以经由正确的节点权重分配得到有益的关系，进而更新出结合关系的区域特征；而错误初始分类的对象的区域特征经过更新之后，错误分配的节点受到错误的关系更新进而降低置信度，正确分配的节点受到正确而有益的关系更新进而提升置信度。但是，经过图注意力层关系传播后的区域特征不仅包含区域本身图像的像素信息，还包含了与其有关系区域的区域特征的一部分，那么对这样的区域特征进行重分类，就需要模型进行额外的学习。因此，在图注意力层的分类器中，加入了两个全连接层和一个Softmax层，用以生成更精准的预测。

而GCN模块的每层预测生成后，就会将新的预测作为下一层节点特征软分类策略的依据输入，将经过传播的新的区域特征输入到更正后的预测分配的节点中，从而开始新的一层区域特征传播。而对于每一层图注意力层，都会使节点获得节点的一阶近邻的特征，那么下一层图注意力层输出的节点事实上包含了节点的二阶近邻的特征。因此，每一个图注意力层的分类器都需要单独训练，因为它们面对了新的、融合了更多其他节点特征的区域特征，应该训练新的参数来适应这一变化。

\section{模型实现细节}

\subsection{CNN模块实现细节}

本模型的CNN模块的卷积网络骨架由ResNet-101\cite{He2016DeepRL}构建。ResNet-101由5个阶段组成，每个阶段对特征图分辨率降维一次，第一阶段为Stem层，将输入通道数为3的图像用步长为2的$7 \times 7$卷积核降维后，输出通道数为64的特征。而第二阶段对特征图分辨率进行降维后将通道数上升到四倍，即256。随后的三个阶段对特征图分辨率进行降维操作后，都将输入特征的通道数上升至两倍，最终，ResNet最后第五阶段输出的通道数为2,048。此外，在ResNet骨架中使用的批标准化层参数都被固定了，在之后的训练过程中不再更新。这是因为本任务中，图像的分辨率较高，则单张显卡上每批输入的图像较少，那么此时批内图像间的统计信息大大减弱，批标准化几乎不起作用，若在后续训练过程中再更新批标准化的参数，反而会降低其效果。

另外，卷积网络骨架上应用了特征金字塔技术，分别从第二到第五个阶段，提取四个不同分辨率的特征来进行特征计算，对这四个阶段的特征进行计算后，输出四个不同特征图分辨率的通道数为256的特征到感兴趣区域对齐层。感兴趣区域对齐层分别对FPN输出的四个不同特征图分辨率的特征，依据各个对象的区域标记，进行感兴趣区域的特征提取，再使用两个全连接层，最终输出特征通道数为1,024的区域特征。

随后，CNN模块将该区域特征直接连接至Softmax分类器，其输出的分类置信率作为基线模型的最终输出，该分类器的损失函数采用交叉熵损失函数。对视觉推理模型来说，使用该区域特征分类器生成的未经Softmax处理的分类置信度，用作GCN模块中软分类策略的权重分配依据。

\subsection{GCN模块实现细节}

GCN模块的软分类策略使用分类置信度排名前$k$的分类的置信度来分配区域特征。在ImageNet图像分类任务中，ResNet-101的top5错误率小于5\%\upcite{He2016DeepRL}，也就是说在该任务的预测结果中，正确的分类大概率会出现在分类置信度排序的前五名里。区域分类任务相对图像分类任务较难，因此本模型对排名前10的分类使用软分类策略。

待某一图注意力层内知识图谱上的节点接受到由软分类策略分配的区域特征后，遍历每一个被激活，即特征不为0的节点，以该节点为中心，对在知识图谱中相连且被激活的节点计算注意力机制，并应用知识图谱边权以及空间距离权重，从而计算出该节点的输出特征。待每一节点的输出特征计算完毕后，将每一区域对应的节点的输出特征相加，得到每一区域的输出特征。将图注意力层输出的区域特征导入带全连接层的分类器，从而生成本图注意力层的分类更正结果。

若无强调，视觉推理模型的GCN模块包含三个注意力层，对每一图注意力层，输入的区域特征维度为1,024，输出到分类器和下一图注意力层的区域特征维度不变，也为1,024。每一图注意力层同时训练8个注意力机，从而使图注意力层的学习更加平稳，加快收敛速度。