% !Mode:: "TeX:UTF-8"
\chapter{网络结构与推理框架}

本章节介绍组成视觉推理模型的整体框架。该框架由CNN模块和GCN模块组成，首先介绍CNN模块的主干设计，随后介绍知识图谱的构建和生成，最后介绍GCN模块的设计以及GCN更新区域特征的方法。

\section{CNN模块的构建}

CNN模块的输入是图像及对象的无标签区域坐标。首先，经由CNN模块的卷积网络主干，提取图像的全局像素特征，然后使用感兴趣区域层，将全局特征依不同对象的区域坐标转化为区域特征，并将区域特征输出到下一模块。除提取特征之外，CNN模块也要做出对各区域分类的初步预测，以将区域特征与不同分类的节点相对应。

本模块使用了多种技术提升特征提取的能力，意图对大部分常见分类，生成较为准确的初始预测。使用这样的预测将区域特征输入GCN模块，GCN模块才可以更好地将区域特征在相应类别的节点间传播。

\subsection{卷积网络主干}

卷积网络主干的设计至关重要，这一部分主要负责提取图像的全局像素特征。在本研究所针对的区域分类任务中，包含所有对象的高分辨率图像直接输入到这一卷积网络进行降维，输出一个通道数较多，而特征图大小较小的高维特征。

受Mask R-CNN启发，本模块使用ResNet作为卷积网络主干，这一模型具备极强的特征提取能力，在以往的计算机视觉研究中得到了充分验证\upcite{He2016DeepRL, He2017MaskR}。ResNet使用残差连接，解决了卷积神经网络在层数较深时的梯度丢失问题，避免了网络的加深反而导致模型拟合能力变差的情况，这一设计使更深的、拟合能力更强的网络成为可能。本研究通过实验对比，选择了101层的ResNet以获得极强的特征提取能力，为模型学习到较难分类的特征提供基础。

本模块所使用的ResNet经过多层降维后，输出特征图到卷积网络主干尾部的特征金字塔网络。这一部分从ResNet的不同阶段接受不同尺寸的输入，从而生成结合不同分辨率特征的高质量特征。特征金字塔网络兼顾了速度与精度，可以充分的提取稀少样本和小样本物体的特征，大大地提升了卷积网络主干的特征提取能力。

\subsection{感兴趣区域层}

输入图像经由卷积网络主干提取全局像素特征后，输出的特征图最小为原分辨率的$1/32$。由于输入图像的分辨率不定，且图像中对象区域的大小也互不相等，则输出的特征图本身的大小就参差不齐，但GCN模块接受的输入应当是固定大小的特征向量。而传统的全连接层针对固定大小的输入设计，无法应用于本研究所处理的区域分类任务。因此，本模块加入了感兴趣区域层对各个大小不一的区域的特征进行提取。该感兴趣区域层使用精准的区域坐标，以及RoI Align层的实现，可以获得较为有效的区域特征。

\section{知识图谱构建}

在使用GCN传播区域特征之前，还需要构建出用于视觉推理的知识图谱$G$，该知识图谱包含不同对象类别之间的人类常识性语义关系与空间关系。知识图谱在模型中起到关键作用，因为它关系着不同类别间的特征沿怎样的路径传播。

\subsection{使用语义关系构建知识图谱}

构建基于语义关系的知识图谱有多种途径。首先，根据VG数据集中提供的标注中出现的对象间关系，如位置关系，主-谓-宾关系等等，结合该关系在对象类别之间共同出现的频率，可以构建出依据关系的知识图谱$G_{R}$。另外，根据VG数据集提供的标注中出现的对象属性，如颜色、材质、形状等等，可以构建出对象类别与属性间的概率分布表\upcite{Xu2019ReasoningRCNNUA}。则对每一对对象类别$c_i$和$c_j$的概率分布$P_{c_i}$与$P_{c_j}$计算Jensen–Shannon散度，就可以得到属性知识图谱$G_{A}$的边$e_{c_{i}, c_{j}}^{A}=J S\left(P_{c_{i}} \| P_{c_{j}}\right)$。

$G_{R}$与$G_{A}$中部分分类间的子图如图\ref{fig:subgraph}所示。当特征在关系知识图谱上$G_{R}$传播时，高置信度的常见分类的节点，就可以通过知识图谱的边对与其相关联的稀少分类节点传播特征，从而丰富稀少分类节点中的特征信息，从而强化其置信率。而与其无关联的节点不会接收到特征的传递，防止特征在分类间泛化，降低模型表现。另外，通过常识得知，属性相近的物体在外观上近似。因为颜色和材质决定了物体表面对光线的反射水平，颜色和材质相近的物体在图像中的像素颜色近似，而外形则影响图像中的形状。如图\ref{fig:subgraph:a}中，摩托车和自行车具有极其相近的属性，其外观也极其相近。而外观相近的物体间存在误认情况，通过属性知识图谱$G_{A}$，使属性相近的物体的分类节点间有特征的传递，可以使预测的置信度趋向由误认分类向正确分类移动。

\begin{figure}[h!]
    \centering
    \subfigure[基于关系的知识图谱]{
        \includegraphics[width=0.45\textwidth]{figure/subgraph_r.png}
        \label{fig:subgraph:r}
    }
    \subfigure[基于属性的知识图谱]{
        \includegraphics[width=0.45\textwidth]{figure/subgraph_a.png}
        \label{fig:subgraph:a}
    }
    \caption{$G_{R}$与$G_{A}$中部分分类间的子图图示}
    \label{fig:subgraph}
\end{figure}

\subsection{使用空间关系构建知识图谱}

\begin{figure}[h!]
    \centering
    \includegraphics[width=.5\textwidth]{figure/kernel.png}
    \caption{核函数$\kappa(x)=\exp (-x / \Delta)$}
    \label{fig:kernel_func}
\end{figure}

根据图像中对象的空间位置关系，可以构建出基于空间的知识图谱$G_{Spatial}$。对象的位置关系分为上下、左右，以及对象区域的包含、重叠等关系。对于对象的上下左右关系，知识图谱边的权重由对象在图像中的像素距离决定，像素距离越远，对象之间的关系越稀疏，因此边的权重应该越低。因此，本研究在节点上应用了核函数$\kappa(x)=\exp (-x / \Delta)$（其中$\Delta = 50$），如图\ref{fig:kernel_func}。对于对象区域的包含或重叠关系，使用图像的交并比（Intersection over Union, IoU）来定义空间关系的边，即对象区域重叠的面积与区域并集面积的比值，IoU越大，代表对象关系越密切。

\section{GCN模块}
