% !Mode:: "TeX:UTF-8"
\chapter{网络结构与推理框架}

本章节介绍组成视觉推理模型的整体框架。该框架由CNN模块和GCN模块组成，首先介绍CNN模块的主干设计，随后介绍知识图谱的构建和生成，最后介绍GCN模块的设计以及GCN更新区域特征的方法。

\section{CNN模块的构建}

CNN模块的输入是图像及对象的无标签区域坐标。首先，经由CNN模块的卷积网络主干，提取图像的全局像素特征，然后使用感兴趣区域层，将全局特征依不同对象的区域坐标转化为区域特征，并将区域特征输出到下一模块。除提取特征之外，CNN模块也要做出对各区域分类的初步预测，以将区域特征与不同分类的节点相对应。

本模块使用了多种技术提升特征提取的能力，意图对大部分常见分类，生成较为准确的初始预测。使用这样的预测将区域特征输入GCN模块，GCN模块才可以更好地将区域特征在相应类别的节点间传播。

\subsection{卷积网络主干}

卷积网络主干的设计至关重要，这一部分主要负责提取图像的全局像素特征。在本研究所针对的区域分类任务中，包含所有对象的高分辨率图像直接输入到这一卷积网络进行降维，输出一个通道数较多，而特征图大小较小的高维特征。

受Mask R-CNN启发，本模块使用ResNet作为卷积网络主干，这一模型具备极强的特征提取能力，在以往的计算机视觉研究中得到了充分验证\upcite{He2016DeepRL, He2017MaskR}。ResNet使用残差连接，解决了卷积神经网络在层数较深时的梯度丢失问题，避免了网络的加深反而导致模型拟合能力变差的情况，这一设计使更深的、拟合能力更强的网络成为可能。本研究通过实验对比，选择了101层的ResNet以获得极强的特征提取能力，为模型学习到较难分类的特征提供基础。

本模块所使用的ResNet经过多层降维后，输出特征图到卷积网络主干尾部的特征金字塔网络。这一部分从ResNet的不同阶段接受不同尺寸的输入，从而生成结合不同分辨率特征的高质量特征。特征金字塔网络兼顾了速度与精度，可以充分的提取稀少样本和小样本物体的特征，大大地提升了卷积网络主干的特征提取能力。

\subsection{感兴趣区域层}

输入图像经由卷积网络主干提取全局像素特征后，输出的特征图最小为原分辨率的$1/32$。由于输入图像的分辨率不定，且图像中对象区域的大小也互不相等，则输出的特征图本身的大小就参差不齐，但GCN模块接受的输入应当是固定大小的特征向量。而传统的全连接层针对固定大小的输入设计，无法应用于本研究所处理的区域分类任务。因此，本模块加入了感兴趣区域层对各个大小不一的区域的特征进行提取。该感兴趣区域层使用精准的区域坐标，以及RoI Align层的实现，可以获得较为有效的区域特征。

\section{知识图谱构建}

在使用GCN传播区域特征之前，还需要构建出用于视觉推理的知识图谱$G$，该知识图谱包含不同对象类别之间的人类常识性语义关系与空间关系。知识图谱在模型中起到关键作用，因为它关系着不同类别间的特征沿怎样的路径传播。

\subsection{使用语义关系构建知识图谱}

\begin{figure}[ht]
    \centering
    \subfigure[基于关系的知识图谱]{
        \includegraphics[width=0.45\textwidth]{figure/subgraph_r.png}
        \label{fig:subgraph:r}
    }
    \subfigure[基于属性的知识图谱]{
        \includegraphics[width=0.45\textwidth]{figure/subgraph_a.png}
        \label{fig:subgraph:a}
    }
    \caption{$G_{R}$与$G_{A}$中部分分类间的子图图示}
    \label{fig:subgraph}
\end{figure}

构建基于语义关系的知识图谱有多种途径。首先，根据VG数据集中提供的标注中出现的对象间关系，如位置关系，主-谓-宾关系等等，结合该关系在对象类别之间共同出现的频率，可以构建出依据关系的知识图谱$G_{R}$。另外，根据VG数据集提供的标注中出现的对象属性，如颜色、材质、形状等等，可以构建出对象类别与属性间的概率分布表\upcite{Xu2019ReasoningRCNNUA}。则对每一对对象类别$i$和$j$的概率分布$P_{i}$与$P_{j}$计算Jensen–Shannon散度，就可以得到属性知识图谱$G_{A}$的边$e_{i j}^{A}=\operatorname{JS} \left(P_{i} \| P_{j}\right)$。

$G_{R}$与$G_{A}$中部分分类间的子图如图\ref{fig:subgraph}所示。当特征在关系知识图谱上$G_{R}$传播时，高置信度的常见分类的节点，就可以通过知识图谱的边对与其相关联的稀少分类节点传播特征，从而丰富稀少分类节点中的特征信息，从而强化其置信率。而与其无关联的节点不会接收到特征的传递，防止特征在分类间泛化，降低模型表现。另外，通过常识得知，属性相近的物体在外观上近似。因为颜色和材质决定了物体表面对光线的反射水平，颜色和材质相近的物体在图像中的像素颜色近似，而外形则影响图像中的形状。如图\ref{fig:subgraph:a}中，摩托车和自行车具有极其相近的属性，其外观也极其相近。而外观相近的物体间存在误认情况，通过属性知识图谱$G_{A}$，使属性相近的物体的分类节点间有特征的传递，可以使预测的置信度趋向由误认分类向正确分类移动。

\subsection{使用空间关系构建知识图谱}

\begin{figure}[ht]
    \centering
    \includegraphics[width=.5\textwidth]{figure/kernel.png}
    \caption{核函数$\kappa(x)=\exp (-x / \Delta)$}
    \label{fig:kernel_func}
\end{figure}

根据图像中对象的空间位置关系，可以构建出基于空间的知识图谱$G_{S}$。对象的位置关系分为上下、左右，以及对象区域的包含、重叠等关系。对于对象的上下、左右关系，知识图谱边的权重由对象在图像中的像素距离决定，像素距离越远，对象之间的关系越稀疏，因此边的权重应该越低。因此，本研究在节点上应用了核函数$\kappa(x)=\exp (-x / \Delta)$（其中$\Delta = 50$），如图\ref{fig:kernel_func}。对于对象区域的包含或重叠关系，还额外使用图像的交并比（Intersection over Union, IoU）来定义空间关系的边，即对象区域重叠的面积与区域并集面积的比值，IoU越大，代表对象关系越密切。

对于对象所在区域$R_i$、$R_j$，上文提到的像素距离$\operatorname{d}\left(R_i, R_j\right)$通过计算原图像中对象区域中心点位置来得到。而对于重叠来说，重叠关系应比普通的上下左右关系更密切，因此边权为计算出像素距离的权重后$d_{i j}$，再加上重叠对象的交并比$\operatorname{IoU}\left(R_i, R_j\right)$。由于未重叠对象的交并比为0，则对任意对象$i$、$j$，其边权的计算如式\ref{Gs_edge}。

\begin{equation} \label{Gs_edge}
    e_{i j}^{S}=\kappa\left(\operatorname{d}\left(R_i, R_j\right)\right) + \operatorname{IoU}\left(R_i, R_j\right)
\end{equation}

在计算出边权后，由于边权为核函数$\kappa(x)$加重叠区域的交并比，对于距离较近且存在重叠现象的区域之间，其对应节点间边的边权可能出现大于1的情况，这会使该节点的权重大于节点的自连接权重。因此，对知识图谱中节点的边权进行标准化，保证其分布在$\left(0, 1\right]$之间。

\section{GCN模块}

GCN模块的结构由三大部分组成：软分类策略、区域特征在GCN上的传播和更新以及对分类的重新预测。

\subsection{软分类策略}

当模型的CNN模块输出各个对象的区域特征时，将区域特征与GCN中知识图谱的节点相对应便是亟待解决的问题。显然，关系存在于物体分类之间，即知识图谱的节点是由物体的分类所定义，而不是由某一张图像中的对象区域所定义的。那么，GCN模块需要将存在于知识图谱中的关系应用在任意一张图像样例上，首先，便需要得到图像样例中对象区域的初步分类。这一分类同样作为CNN模块的输出，是由CNN模块在提取特征后，应用一个分类器独自生成的。然后，将区域特征由区域特征生成的分类，分配至相应的知识图谱的节点上。

但是，错误的初始分类预测会导致区域特征被分配至错误的节点上。而在高难度的VG测试集上，一张样例上$50\%$左右的初始分类预测都是错误的。错误的初始分类会导致区域特征在错误分类的节点间传播，而知识图谱中的关系就难以利用。因此，相对于只将特征传递给初始分类预测中的最可信分类，本研究使用了软分类策略分配区域特征。

首先，对初始分类结果置信度排序的前$k$个分类分别计算Softmax值$S_{i}$。如式\ref{softmax}，其中$e^{i}$代表分类器输出的第$i$个分类的置信度。

\begin{equation} \label{softmax}
    S_{i}=\frac{e^{i}}{\sum_{j} e^{j}}
\end{equation}

由此得到前$k$个分类的置信概率分布，依此置信概率为分配权重，将区域特征按比例分配到相应的节点中。

因为正确的分类往往都会出现在初始结果预测的前$k$个，因此正确的节点就有很大概率接收到该物体的区域特征。即使错误的初始分类会使正确的节点接收到较少的区域特征，但随着区域特征沿关系传播，正确的分类之间存在着关系，则正确的节点的置信度会由此而提高，错误的节点的置信度也会下降。因此，使用软分类策略可以使模型对错误的分类更加鲁棒，增强模型纠正初始预测错误的能力。

\subsection{区域特征在GCN上的传播}

当区域特征由CNN模块正确地通过软分类策略分配到知识图谱的各个节点上时，下一步就是让知识图谱节点上的特征沿知识图谱的边进行传播，在特征进行传播后，要进入分类预测器生成新的预测。知识图谱中的关系是不规则的，对单个节点所表示的对象来说，其关系的多寡是依据现实情况决定的。而我们需要将知识图谱中的不规则的关系融入各个节点区域的特征，更新区域特征后，融入了关系的特征就可以提升分类预测的准确率。受近年来在图卷积网络领域十分热门的图注意力网络\cite{Velickovic2018GraphAN}启发，本研究使用图注意力层作为本模块中传播区域特征的层。

\subsubsection{图注意力层}

图注意力层的输入是一个节点区域特征组成的集合，$\mathbf{h}=\left\{\vec{h}_{1}, \vec{h}_{2}, \ldots, \vec{h}_{N}\right\}, \vec{h}_{i} \in \mathbb{R}^{F}$，其中$N$为节点数量，在本任务中即为分类数量，$F$即为每个节点特征向量的长度。经过特征传播运算后，图注意力层输出新的特征集合$\mathbf{h}^{\prime}=\left\{\vec{h}_{1}^{\prime}, \vec{h}_{2}^{\prime}, \ldots, \vec{h}_{N}^{\prime}\right\}, \vec{h}_{i}^{\prime} \in \mathbb{R}^{F^{\prime}}$，其中$F^{\prime}$为输出特征的维度，根据实际情况可与输入特征的维度$F$相同或不同。

对于一个深度学习模型而言，可训练的参数是它学习到提取特征能力的必要因素。而图注意力层有两个可学习的参数，权重矩阵$\mathbf{W} \in \mathbb{R}^{F^{\prime} \times F}$与注意力机$\vec{\mathbf{a}} \in \mathbb{R}^{2 F^{\prime}}$。对于每个节点$i$，定义$\mathcal{N}_{i}$为所有节点$i$的一阶近邻，包括其自身。图注意力层应用了注意力机制，可以学习到节点与其一阶近邻传播特征的权重。对每个节点$j \in \mathcal{N}_{i}$，计算一个注意力系数$\alpha_{i j}$，如式\ref{GAT:attention}。

\begin{equation} \label{GAT:attention}
    \alpha_{i j}=\frac{\exp \left(\operatorname{LeakyReLU} \left(\vec{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{j}\right]\right)\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(\operatorname{LeakyReLU}\left(\vec{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| \mathbf{W} \vec{h}_{k}\right]\right)\right)}
\end{equation}

式中$\|$为向量拼接操作，操作$T$为矩阵转置，$\operatorname{LeakyReLU}(\cdot)$为非线性激活函数（参数$\alpha$为0.2），如式\ref{GAT:LeakyReLU}。将$\mathbf{W} \vec{h}_{i} \in \mathbb{R}^{F^{\prime} \times 1}$与$\mathbf{W} \vec{h}_{j} \in \mathbb{R}^{F^{\prime} \times 1}$沿第0维拼接后，与注意力机$\vec{\mathbf{a}}$做乘法运算得出节点$j$对$i$的注意力分量，再与所有节点的注意力分量之和做Softmax运算，得出注意力系数$\alpha_{i j}$。此时很容易看出，节点$i$的所有一阶近邻节点的注意力系数之和为1。

\begin{equation} \label{GAT:LeakyReLU}
    \operatorname{LeakyReLU}(x)=\left\{\begin{array}{ll}
    x, & x \geq 0 \\
    \alpha x, & x<0
    \end{array} \in R\right.
\end{equation}

那么便可以计算出节点$i$的输出特征向量$\vec{h}_{i}^{\prime}$，如式\ref{GAT:output1}，其中$\sigma(\cdot)$为非线性激活函数。

\begin{equation} \label{GAT:output1}
    \vec{h}_{i}^{\prime}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} \mathbf{W} \vec{h}_{j}\right)
\end{equation}

此外，参考CNN中卷积核的通道数，图注意力层也可以使用类似的机制，构建多个图注意力机$\vec{\mathbf{a}}_{k}$和权重矩阵$\mathbf{W}_{k}$，使训练过程更稳定，收敛更迅速。最终输出的特征向量为$k$个图注意力机输出的特征向量的拼接或均值。

\subsubsection{区域特征的传播}

由于知识图谱中每一个分类都对应最少一个节点，实际上，依数据集不同，分类数量在数十到上万不等。若对全部节点计算注意力机制，势必会消耗极多的运算资源和内存。但对单张图像样例来说，即使应用了软分类机制，图像中对象区域对应的节点数量也会远小于总分类节点。因此，当样例中的对象区域的特征依软分类机制被分配到对应的节点上之后，其他没有被对应的节点的特征值全部赋值为0，在计算时也不以其为中心节点。这样大部分无意义节点就会被跳过，节省运算资源的同时，也不会影响区域特征的传播。

此外，基于一个常识性假设，图像中距离相近的物体分类之间具备语义关系的概率较大，而较远的物体分类间即使具备语义关系，也很有可能是巧合。如人与自行车两个对象，若二者距离较近，其可能发生的是人驾驶自行车的语义关系，但若实际情况中，自行车与人之间存在很远的间隔，那么二者的驾驶关系就十分微弱乃至不成立。除驾驶关系外，大部分的语义关系都发生于较近的对象之间，则为了防止这样错误的传播出现，应在应用语义关系时加入空间关系，来削弱距离较远的巧合情况，增强距离较近的强语义关系，从而改善对语义关系的利用。

因此，在计算特征传播的过程中，在知识图谱边权$e_{i j}$的基础上，额外加入一个像素距离权重$d_{i j}$，该权重的计算方式与空间知识图谱$G_{S}$的边权$e_{i j}^{S}$一致，如式\ref{Gs_edge}。则本模型中，节点$i$的特征向量$\vec{h}_{i}$经过一次传播后，输出特征向量$\vec{h}_{i}^{\prime}$的计算如式\ref{GAT:output2}。

\begin{equation} \label{GAT:output2}
    \vec{h}_{i}^{\prime}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} e_{i j} d_{i j} \mathbf{W} \vec{h}_{j}\right)
\end{equation}

因此，对注意力系数的计算改进为式\ref{GAT:attention2}，特别的，对节点$i$的区域特征$\vec{h}_{i}$，其距离权重$d_{i i}$和知识图谱边权$e_{i i}$均为1。将空间距离和知识图谱关系权重对近邻特征$\vec{h}_{j}$的影响加入计算，这样可以使注意力机学习到不同重要性的近邻对中心节点的区域特征传播的重要性不同，对重要性较高的近邻分配更多的传播注意力，这可以有效避免错误或不重要的关系，如较远的物体、多层传播中的非一阶近邻节点等对区域特征的传播产生过多的副作用。

\begin{equation} \label{GAT:attention2}
    \alpha_{i j}=\frac{\exp \left(\operatorname{LeakyReLU} \left(\vec{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| e_{i j} d_{i j} \mathbf{W} \vec{h}_{j}\right]\right)\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(\operatorname{LeakyReLU}\left(\vec{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} \| e_{i k} d_{i k} \mathbf{W} \vec{h}_{k}\right]\right)\right)}
\end{equation}

若一张样例中，同时出现多个区域被分类到某个节点，在传播时会对这个节点的不同区域特征进行多次计算。实际计算时，将每个区域特征都当做一个新节点。对节点$i$进行计算时，各个相同分类的节点的关系连接权重$e_{i j}$使用知识图谱中此分类对应的边权，如果节点$i$本身有相同分类的节点，便使用知识图谱中的自连接权重进行传播，而对注意力系数$\alpha_{i j}$和距离权重$d_{i j}$，每个节点独立进行计算。另外基于软分类策略，每个区域特征都对应了多个节点，在分别计算这一区域的各个节点的输出特征后，将各个节点的输出特征相加，输出为本区域的输出特征。

\subsection{分类的重新预测}

在CNN模块的感兴趣区域层，或GCN模块的图注意力层计算出某一阶段的区域特征后，模型都会使用分类器对区域进行分类。区域特征经过图注意力层传播之后，初始分类正确的对象可以经由正确的节点权重分配得到有益的关系，进而更新出结合关系的区域特征；而错误初始分类的对象的区域特征经过更新之后，错误分配的节点受到错误的关系更新进而降低置信度，正确分配的节点受到正确而有益的关系更新进而提升置信度。但是，经过图注意力层关系传播后的区域特征不仅包含区域本身图像的像素信息，还包含了与其有关系区域的区域特征的一部分，那么对这样的区域特征进行重分类，就需要模型进行额外的学习。因此，在图注意力层的分类器中，加入了两个全连接层和一个Softmax层，用以生成更精准的预测。

而GCN模块的每层预测生成后，就会将新的预测作为下一层节点特征软分类策略的依据输入，将经过传播的新的区域特征输入到更正后的预测分配的节点中，从而开始新的一层区域特征传播。而对于每一层图注意力层，都会使节点获得节点的一阶近邻的特征，那么下一层图注意力层输出的节点事实上包含了节点的二阶近邻的特征。因此，每一个图注意力层的分类器都需要单独训练，因为它们面对了新的、融合了更多其他节点特征的区域特征，应该训练新的参数来适应这一变化。

对分类器的最后一层，应用了Softmax函数输出对分类的概率分布，分别对每个分类器使用交叉熵损失函数训练。