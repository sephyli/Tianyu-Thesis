% !Mode:: "TeX:UTF-8"

% 中英文摘要
\begin{cabstract}
本研究提出了一个基于GCN知识图谱分析的视觉推理模型，该模型弥补了传统的目标检测卷积网络模型和框架仅使用图片的像素信息对图像进行分析的不足，使用GCN对人类常识性知识图谱中的物体关系进行分析，将图片中的语义信息融入模型，使模型具有视觉推理的能力。本模型由两个主要模块组成，分别是CNN模块和GCN模块：CNN模块由ResNet构建而成，具备着极强的提取图像像素特征的能力；GCN模块由图注意力网络构建而成，可以使特征在图结构的知识图谱上进行传播。模型多次结合CNN模块与GCN模块的预测结果，对物体进行重新分类以提升准确率。知识图谱的构建使用到了多种关系信息，包括物体的常识性语义关系、物体属性的相关度和物体的空间关系三种。本视觉推理模型表现出了远超传统卷积模型的能力，相对其它最新技术也有小幅提升。在VG测试集上的区域分类任务中，样例平均精度(AP)比传统卷积模型取得了$4.25\%$的绝对提升。
\end{cabstract}

\begin{eabstract}

\end{eabstract}