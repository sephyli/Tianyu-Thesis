% !Mode:: "TeX:UTF-8"
\chapter{实验}

\section{数据集和评判标准}

\subsection{数据集处理}

Visual Genome数据集\cite{Krishna2016VisualGC}包含了众多高质量的标注信息，包括对象信息、对象属性信息、对象间关系信息等，对本研究探寻对象间关系带来很大便利，因此本研究采用VG数据集中的标注信息对数据集进行关系分析、属性相关度分析等。VG数据集由108,077张图片样例组成，被分割成100,000张训练样例、4077张验证样例、以及4000张测试样例，平均每张图片中出现21.24个对象，17.68个关系连接以及16.08个属性标注信息。由于VG数据集使用了不同的标注器进行标注，其原始分类中有多种对同一物体的不同叫法，如对人来说有man、person等多种叫法且分布广泛，因此首先使用同义词集将VG数据集中的标注信息进行统一。另外，VG数据集中有着众多的物体标注，以至于存在太多稀少的分类，如表\ref{tab:dataset_cat}所示，在众多目标检测数据集中，VG数据集有超过80,000个分类数量，这大大超出了正常目标检测模型的能力。因此，本研究只选取了VG数据集数量最多的前1,000个分类，即使如此也远超其它检测数据集，这也代表了VG数据集的难度较高，稀少分类较多。

\begin{table}[ht]
    \centering
    \caption{各种检测数据集的对象分类情况对比}
    \label{tab:dataset_cat}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llllllll@{}}
    \toprule
     & VisualGenome & ImageNet Detection & MS COCO & Caltech 101 & Caltech 256 & Caltech Pedestrian & PASCAL Detection \\ \midrule
    图像数量 & 107,228 & 476,688 & 328,000 & 9,144 & 30,608 & 250,000 & 11,530 \\
    对象数量 & 3,909,697 & 534,309 & 2,500,000 & 9,144 & 30,608 & 350,000 & 27,450 \\
    分类数量 & 80,138 & 200 & 91 & 102 & 257 & 1 & 20 \\
    每分类图像数量 & 48.79 & 2671.5 & 27472.5 & 90 & 119 & 350,000 & 1372.5 \\ \bottomrule
    \end{tabular}%
    }
\end{table}

\subsection{任务和评判标准}

在实验中，本研究验证了模型在区域分类任务\cite{Chen2018IterativeVR}下的有效性。区域分类任务是指对输入的含有矩形区域标注的图像内的区域进行分类的任务，因此在训练过程和验证、测试过程中，模型的输入是包含对象区域标注的图像，输出为对各个区域的分类。区域标注直接使用了VG数据集中的对象标注信息。

区域分类任务看上去是目标检测任务的简化版。目标检测任务并不提供区域标注，模型本身还需要完成对区域的预测。但本研究所使用的VG数据集分类数量繁多，且大量存在不完全标注的信息。在很多图像样例中，对人的标注不仅有人本身，还有人身体的一部分，如肢体、头发等，而在另一些图像样例中，却仅仅对整个人进行了标注。这导致模型在VG数据集上进行对区域的预测时，会在这样部分标注的信息中产生冲突，对有些图像，会多预测出原图像没有标注的对象。对VG数据集而言，这会对模型的准确度产生负面影响。另外，对关系的利用是与区域强相关的，本研究旨在表明对关系的运用以及区域信息在知识图谱上传播对模型正确分类对象有所帮助。虽然可以很简单直接应用某一个目标检测框架，并在其后应用本研究的GCN模块，但现有的目标检测框架使用的很多方法反而会降低GCN模块对关系的利用。比如非极大值抑制(Nonmaximal Suppression)，被目标检测模型用以消除预测出来的重叠较大的区域，但它往往也会消除距离较近、关系较密切的物体的区域，比如人行道和马路、窗户和窗帘、百叶窗等。再比如，存在一些数量关系的样例，如路边的三棵树被标记成三个树（tree）对象，和一个整体的“树们”（trees）对象。目标检测模型会消除这些对象，是因为它针对的数据集往往是分类数量较少的数据集，如PASCAL Voc等，但这些被消除的对象恰恰是本模型通过关系知识图谱，意图提升的稀少分类的对象。因此本研究选择区域分类任务，着重于展现关系知识图谱使视觉模型具备视觉推理能力的作用。

在VG验证集和测试集上，我们采用分类正确率（Accuracy，AC）和平均精度（Average Precision，AP）\cite{Everingham2009ThePV}两个指标。特别地，由于区域分类任务下的区域标注是绝对精准的，则平均精度中关于区域预测IoU的阈值设定就无效了。对于每种指标，都有两种方式来进行统计，“每分类”和“每样例”，前者是将AC或AP在全部分类上取平均，后者是将AC或AP在单张样例中取平均后统计得出。相对来说，“每分类”的统计方式更能体现出模型在稀有分类下的表现。

\section{训练参数设置}

一个经过改进的广义Faster R-CNN系列模型\cite{Ren2015FasterRT, He2017MaskR, massa2018mrcnn}用以构建本研究的基线模型(baseline)。由于本模型针对的是区域分类任务，因此基线模型中删除掉了该系列模型中的区域推理网络分支及用以预测区域偏移量的回归器。在为基线模型加入了特征金字塔技术之后，事实上基线模型就与单独的CNN模块等价。在基线模型和视觉推理模型的CNN模块中，卷积网络骨架都使用了ResNet-101\cite{He2016DeepRL}。

ResNet-101使用微软亚洲研究院（Microsoft Research Asia，MSRA）发布的ImageNet预训练模型进行参数初始化，使用带动量的随机梯度下降法（Stochastic Gradient Descent ，SGD）作为所有模型的优化器对模型进行训练，其中动量系数（momentum）为0.9，权重衰减率（Weight Decay）为$1 e^{-3}$，应用带热身轮的线性下降学习率衰减法。对于4GPU训练来说，基础学习率为$1 e^{-3}$，每个批16张训练用例，训练90,000个轮次(iters)。对于2GPU训练，基础学习率为$5 e^{-4}$，每个批8张训练用例，训练180,000个轮次。

\section{实验结果}

如表\ref{tab:result1}，本研究提出的视觉推理模型相对基线方法体现了显著优势，其中$G_{R, S}$代表应用了带距离权重的常识性关系知识图谱的视觉推理模型。每样例与每类别的评价指标AC与AP皆有明显提升。其中，每类别AC的相对提升幅度较大，可达到$12.4\%$，而每样例AC相对提升$7.6\%$。每类别AP相对提升$9.5\%$，而每样例AP相对提升$8.0\%$。在AC、AP两个指标上，每样类别的相对提升幅度都较大，这说明视觉推理模型针对稀有分类有额外的提升效果，特征在关系知识图谱上的传播有效地提升了稀有分类的识别效果。

\begin{table}[ht]
    \centering
    \caption{在VG-1000测试集上的主要结果}
    \label{tab:result1}
    \begin{tabular}{c|l|ll|ll}
    \toprule
    \multirow{2}{*}{\%} & \multirow{2}{*}[-0.5ex]{方法} & \multicolumn{2}{c|}{每样例} & \multicolumn{2}{c}{每类别} \\ \cline{3-6} 
        &  & \multicolumn{1}{c}{AP} & \multicolumn{1}{c|}{AC} & \multicolumn{1}{c}{AP} & \multicolumn{1}{c}{AC} \\ \hline
    \multirow{2}{*}[-0.5ex]{VG-1000} & 基线 & $52.8$ & $53.2$ & $30.3$ & $27.7$ \\ \cline{2-6} 
        & $\text{视觉推理}_{G_{R, S}}$ & $57.1^{+4.3}$ & $57.3^{+4.1}$ & $33.2^{+2.9}$ & $31.2^{+3.4}$ \\ \bottomrule
    \end{tabular}
\end{table}

由于视觉推理模型相比基线模型多了三层图注意力层，增加的参数可能是模型表现增强的原因。于是我们构建了在分类器前加入三层参数相同的全连接层的对比模型。由实验结果得知，加入全连接层并不会使模型的表现有极大提升，证明了GCN模块中图注意力层对关系的传播有利于分类任务，而图注意力层相对全连接层显现了显著的优势。这是由于图注意力层之中的知识图谱蕴含了包含关系的先验知识，即特征按照关系来传播。而全连接层特征不定向传播，输出特征为全部输入特征的线性组合。

\begin{table}[ht]
    \centering
    \caption{加入全连接层的基线对比}
    \label{tab:result2}
    \begin{tabular}{c|l|ll|ll}
    \toprule
    \multirow{2}{*}{\%} & \multirow{2}{*}[-0.5ex]{方法} & \multicolumn{2}{c|}{每样例} & \multicolumn{2}{c}{每类别} \\ \cline{3-6} 
     &  & \multicolumn{1}{c}{AP} & \multicolumn{1}{c|}{AC} & \multicolumn{1}{c}{AP} & \multicolumn{1}{c}{AC} \\ \hline
    \multirow{3}{*}{VG-1000} & 基线 & $52.8$ & $53.2$ & $30.3$ & $27.7$ \\
     & $\text{基线}_{+3fc}$ & $53.1^{+0.3}$ & $53.4^{+0.2}$ & $30.4^{+0.1}$ & $27.8^{+0.1}$ \\ \cline{2-6} 
     & $\text{视觉推理}_{G_{R, S}}$ & $57.1^{+4.3}$ & $57.3^{+4.1}$ & $33.2^{+2.9}$ & $31.2^{+3.4}$ \\ \bottomrule
    \end{tabular}
\end{table}

不同的知识图谱加强模型表现的能力不同。由表\ref{tab:result3}，可以看到，只应用空间知识图谱和应用了属性知识图谱和空间距离权重的两个模型提升幅度较小。属性知识图谱的连接十分密集，因为使用JS散度度量对象间的属性分布相关度，这导致即使及其不相关的对象间，仍有连接存在。而空间知识图谱直接在单张样例的整张图上对所有区域计算像素距离，这导致每个区域之间都具备连接。这二者的连接都较为密集，特征传播几乎没有选择性，只不过分配了相应的权重，具备一定的先验知识。这也导致其相对加了三全连接层的基线模型提升较小，但明显可见，在每类别的度量指标中提升幅度较大，说明知识图谱对稀少分类还是具备提升的作用。稀少分类往往存在于物体的一部分或附近，基于距离或属性的知识图谱对稀少分类的特征传播分配仍然可以使模型对稀少分类具备更强的识别能力。

\begin{table}[ht]
    \centering
    \caption{不同知识图谱下的模型表现}
    \label{tab:result3}
    \begin{tabular}{c|l|ll|ll}
    \toprule
    \multirow{2}{*}{\%} & \multirow{2}{*}[-0.5ex]{方法} & \multicolumn{2}{c|}{每样例} & \multicolumn{2}{c}{每类别} \\ \cline{3-6} 
     &  & \multicolumn{1}{c}{AP} & \multicolumn{1}{c|}{AC} & \multicolumn{1}{c}{AP} & \multicolumn{1}{c}{AC} \\ \hline
    \multirow{4}{*}{VG-1000} & 基线 & $52.8$ & $53.2$ & $30.3$ & $27.7$ \\ \cline{2-6} 
     & $\text{视觉推理}_{G_{S}}$    & $54.6^{+1.8}$ & $55.0^{+1.8}$ & $31.7^{+1.4}$ & $28.4^{+0.7}$ \\
     & $\text{视觉推理}_{G_{A, S}}$ & $53.4^{+0.6}$ & $53.6^{+0.4}$ & $30.8^{+0.5}$ & $29.0^{+1.3}$ \\
     & $\text{视觉推理}_{G_{R, S}}$ & $57.1^{+4.3}$ & $57.3^{+4.1}$ & $33.2^{+2.9}$ & $31.2^{+3.4}$ \\ \bottomrule
    \end{tabular}
\end{table}

带关系知识图谱的图注意力层可以极大地利用语义关系来提升模型的分类能力。接下来，表\ref{tab:result4}展示了分别增加一个、两个、三个图注意力层对模型表现的影响。可以看到随着层数的堆叠，模型的表现有着轻微的上升，但使用一层图注意力层时，模型就已经从一阶关系中受益，而更高阶的语义关系对模型的提升会相对较弱。尤其对稀有分类，节点的一阶近邻与其关系最密切，而二阶乃至三阶近邻事实上已经覆盖了很多其它的无关节点，但由于图注意力层的注意力机制，使得模型对关系较密切的区域着重传播特征，避免了无关节点对区域特征有过多的负面影响。

\begin{table}[ht]
    \centering
    \caption{不同层数的图注意力层对视觉推理模型表现的影响}
    \label{tab:result4}
    \begin{tabular}{c|l|ll|ll}
    \hline
    \multirow{2}{*}{\%} & \multirow{2}{*}[-0.5ex]{方法} & \multicolumn{2}{c|}{每样例} & \multicolumn{2}{c}{每类别} \\ \cline{3-6} 
     &  & \multicolumn{1}{c}{AP} & \multicolumn{1}{c|}{AC} & \multicolumn{1}{c}{AP} & \multicolumn{1}{c}{AC} \\ \hline
    \multirow{5}{*}{VG-1000} & 基线 & $52.8$ & $53.2$ & $30.3$ & $27.7$ \\ \cline{2-6} 
     & $\text{视觉推理}_{G_{R, S}}$ & & & & \\
     & \hspace{3em}- 1层 & $55.9^{+3.1}$ & $56.4^{+3.2}$ & $32.5^{+2.2}$ & $30.4^{+2.7}$ \\
     & \hspace{3em}- 2层 & $56.6^{+3.8}$ & $56.9^{+3.7}$ & $32.8^{+2.5}$ & $30.8^{+3.1}$ \\
     & \hspace{3em}- 3层 & $57.1^{+4.3}$ & $57.3^{+4.1}$ & $33.2^{+2.9}$ & $31.2^{+3.4}$ \\ \hline
    \end{tabular}
\end{table}

经上述实验研究得出，使用GCN与知识图谱分析的视觉推理模型可以有效提高视觉模型的分类能力。其中知识图谱的构建起到了关键作用，只有合适的知识图谱才可以大大提升模型的视觉推理能力。图注意力层对区域特征在知识图谱上的传播起到了较大作用，自注意力策略可以在一定程度上增强传播过程中对关系的筛选作用。

% \begin{table}[ht]
%     \centering
%     \caption{实验汇总}
%     \label{tab:result5}
%     \begin{tabular}{c|l|ll|ll}
%     \toprule
%     \multirow{2}{*}{\%} & \multirow{2}{*}[-0.5ex]{方法} & \multicolumn{2}{c|}{每样例} & \multicolumn{2}{c}{每类别} \\ \cline{3-6} 
%      &  & \multicolumn{1}{c}{AP} & \multicolumn{1}{c|}{AC} & \multicolumn{1}{c}{AP} & \multicolumn{1}{c}{AC} \\ \hline
%     \multirow{8}{*}{VG-1000} & 基线 & $52.8$ & $53.2$ & $30.3$ & $27.7$ \\
%      & $\text{基线}_{+3fc}$ & $53.1^{+0.3}$ & $53.4^{+0.2}$ & $30.4^{+0.1}$ & $27.8^{+0.1}$ \\ \cline{2-6} 
%      & $\text{视觉推理}_{G_{S}}$    & $54.6^{+1.8}$ & $55.0^{+1.8}$ & $31.7^{+1.4}$ & $28.4^{+0.7}$ \\
%      & $\text{视觉推理}_{G_{A, S}}$ & $53.4^{+0.6}$ & $53.6^{+0.4}$ & $30.8^{+0.5}$ & $29.0^{+1.3}$ \\
%      & $\text{视觉推理}_{G_{R, S}}$ & & & & \\
%      & \hspace{3em}- 1层 & $55.9^{+3.1}$ & $56.4^{+3.2}$ & $32.5^{+2.2}$ & $30.4^{+2.7}$ \\
%      & \hspace{3em}- 2层 & $56.6^{+3.8}$ & $56.9^{+3.7}$ & $32.8^{+2.5}$ & $30.8^{+3.1}$ \\
%      & \hspace{3em}- 3层 & $57.1^{+4.3}$ & $57.3^{+4.1}$ & $33.2^{+2.9}$ & $31.2^{+3.4}$ \\ \bottomrule
%     \end{tabular}
% \end{table}