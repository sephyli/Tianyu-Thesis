% !Mode:: "TeX:UTF-8"
\chapter{实验}

\section{数据集和评判标准}

\subsection{数据集处理}

Visual Genome数据集\cite{Krishna2016VisualGC}包含了众多高质量的标注信息，包括对象信息、对象属性信息、对象间关系信息等，对本研究探寻对象间关系带来很大便利，因此本研究采用VG数据集中的标注信息对数据集进行关系分析、属性相关度分析等。VG数据集由108,077张图片样例组成，被分割成100,000张训练样例、4077张验证样例、以及4000张测试样例，平均每张图片中出现21.24个对象，17.68个关系连接以及16.08个属性标注信息。由于VG数据集使用了不同的标注器进行标注，其原始分类中有多种对同一物体的不同叫法，如对人来说有man、person等多种叫法且分布广泛，因此首先使用同义词集将VG数据集中的标注信息进行统一。另外，VG数据集中有着众多的物体标注，以至于存在太多稀少的分类，如表\ref{tab:dataset_cat}所示，在众多目标检测数据集中，VG数据集有超过80,000个分类数量，这大大超出了正常目标检测模型的能力。因此，本研究只选取了VG数据集数量最多的前1,000个分类，即使如此也远超其它检测数据集，这也代表了VG数据集的难度较高，稀少分类较多。

\begin{table}[h!]
    \centering
    \caption{各种检测数据集的对象分类情况对比}
    \label{tab:dataset_cat}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llllllll@{}}
    \toprule
     & VisualGenome & ImageNet Detection & MS COCO & Caltech 101 & Caltech 256 & Caltech Pedestrian & PASCAL Detection \\ \midrule
    图像数量 & 107,228 & 476,688 & 328,000 & 9,144 & 30,608 & 250,000 & 11,530 \\
    对象数量 & 3,909,697 & 534,309 & 2,500,000 & 9,144 & 30,608 & 350,000 & 27,450 \\
    分类数量 & 80,138 & 200 & 91 & 102 & 257 & 1 & 20 \\
    每分类图像数量 & 48.79 & 2671.5 & 27472.5 & 90 & 119 & 350,000 & 1372.5 \\ \bottomrule
    \end{tabular}%
    }
\end{table}

\subsection{任务和评判标准}

在实验中，本研究验证了模型在区域分类任务\cite{Chen2018IterativeVR}下的有效性。区域分类任务是指对输入的含有矩形区域标注的图像内的区域进行分类的任务，因此在训练过程和验证、测试过程中，模型的输入是包含对象区域标注的图像，输出为对各个区域的分类。区域标注直接使用了VG数据集中的对象标注信息。

区域分类任务看上去是目标检测任务的简化版。目标检测任务并不提供区域标注，模型本身还需要完成对区域的预测。但本研究所使用的VG数据集分类数量繁多，且大量存在不完全标注的信息。在很多图像样例中，对人的标注不仅有人本身，还有人身体的一部分，如肢体、头发等，而在另一些图像样例中，却仅仅对整个人进行了标注。这导致模型在VG数据集上进行对区域的预测时，会在这样部分标注的信息中产生冲突，对有些图像，会多预测出原图像没有标注的对象。对VG数据集而言，这会对模型的准确度产生负面影响。另外，对关系的利用是与区域强相关的，本研究旨在表明对关系的运用以及区域信息在知识图谱上传播对模型正确分类对象有所帮助。虽然可以很简单直接应用某一个目标检测框架，并在其后应用本研究的GCN模块，但现有的目标检测框架使用的很多方法反而会降低GCN模块对关系的利用。比如非极大值抑制(Nonmaximal Suppression)，被目标检测模型用以消除预测出来的重叠较大的区域，但它往往也会消除距离较近、关系较密切的物体的区域，比如人行道和马路、窗户和窗帘、百叶窗等。再比如，存在一些数量关系的样例，如路边的三棵树被标记成三个树（tree）对象，和一个整体的“树们”（trees）对象。目标检测模型会消除这些对象，是因为它针对的数据集往往是分类数量较少的数据集，如PASCAL Voc等，但这些被消除的对象恰恰是本模型通过关系知识图谱，意图提升的稀少分类的对象。因此本研究选择区域分类任务，着重于展现关系知识图谱使视觉模型具备视觉推理能力的作用。

在VG验证集和测试集上，我们采用分类正确率（Accuracy，AC）和平均精度（Average Precision，AP）\cite{Everingham2009ThePV}两个指标。特别地，由于区域分类任务下的区域标注是绝对精准的，则平均精度中关于区域预测IoU的阈值设定就无效了。对于每种指标，都有两种方式来进行统计，“每分类”和“每样例”，前者是将AC或AP在全部分类上取平均，后者是将AC或AP在单张样例中取平均后统计得出。大体来说，“每分类”的统计方式更能体现出模型在稀有分类下的表现。

\section{实现细节}

